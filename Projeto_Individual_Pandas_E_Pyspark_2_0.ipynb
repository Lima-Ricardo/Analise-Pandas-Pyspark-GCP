{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqu1u3ikjLyB+5ICDBsvju",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lima-Ricardo/Analise-Pandas-Pyspark-GCP/blob/main/Projeto_Individual_Pandas_E_Pyspark_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Item postado em 09:36 Editado às 09:45\n",
        "Atribuído\n",
        "Nivel Infra\n",
        "O Dataset deve ser salvo em ambiente cloud(Cloud Storage)\n",
        "O arquivo original e tratado deve ser salvo em MongoDB Atlas em coleções diferentes\n",
        "Os DataFrames devem ser obrigatoriamente salvos em uma bucket do CloudStorage\n",
        "\n",
        "Nivel Pandas\n",
        "O arquivo está em outra linguagem e deve ter seus dados traduzidos para Português-BR\n",
        "Realizar a extração corretamente para um dataframe\n",
        "Verificar a existência de dados inconsistentes e realizar a limpeza para NaN ou NA\n",
        "Realizar o drop(se necessário) de colunas do dataframe realizando o comentário do porque da exclusão \n",
        "Todos os passos devem ser comentados\n",
        "Nivel PySpark (Funções básicas vistas em aula)\n",
        "Deverá ser montada a estrutura do DataFrame utilizando o StructType.\n",
        "Verificar a existência de dados inconsistentes, nulos e realizar a limpeza.\n",
        "Verificar a necessidade de drop em colunas ou linhas. Caso seja necessário, fazer comentário do porque.\n",
        "Realizar a mudança de nome de pelo menos 2 colunas\n",
        "Deverá criar pelo menos duas novas colunas contendo alguma informação relevante sobre as outras colunas já existentes (Funções de Agrupamento, Agregação ou Joins). (Use a sua capacidade analítica)\n",
        "Deverá utilizar filtros, ordenação e agrupamento, trazendo dados relevantes para o negócio em questão. (Use a sua capacidade analítica)\n",
        "Utilizar pelo menos duas Window Functions\n",
        "Nivel SparkSQL\n",
        "Utilizar no minimo 5 consultas diferentes utilizando o SparkSQL, comentando o porquê de ter escolhido essas funções e explicando o que cada consulta faz.\n",
        "Nível DataStudio\n",
        "Construir um dashboard (maximo 1 pagina) para apresentação dos insights\n",
        "\n",
        "Ferramentas\n",
        "\n",
        "\n",
        "Colab ou Ides | Google Cloud | Data Studio***"
      ],
      "metadata": {
        "id": "VEZk_whASMH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Intalando as libs necessárias para o projeto***"
      ],
      "metadata": {
        "id": "FknBOnR2S-V4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6d4Mu55HLMf",
        "outputId": "2def1f60-cb29-4b28-f628-0cb3d20a9db1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gcsfs\n",
            "  Downloading gcsfs-2022.5.0-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (4.4.2)\n",
            "Collecting aiohttp<4\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 17.6 MB/s \n",
            "\u001b[?25hCollecting fsspec==2022.5.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 19.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (1.35.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (from gcsfs) (1.18.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gcsfs) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.7/dist-packages (from gcsfs) (0.4.6)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 16.8 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 54.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (2.0.12)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (21.4.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4->gcsfs) (4.2.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.2.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp<4->gcsfs) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2022.5.18.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->gcsfs) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->gcsfs) (0.4.1)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (1.31.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (1.56.2)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (21.3)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (3.17.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (2022.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->gcsfs) (3.0.9)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, gcsfs\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.5.0 gcsfs-2022.5.0 multidict-6.0.2 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gcsfs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llAtg4--IUoB",
        "outputId": "bedb6399-b01b-43e3-9172-32ed83cbbecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWJv3ghpJx4q",
        "outputId": "7f4d9782-dcd5-4762-eba8-5c71014b8843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 27 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 39.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=52ea26654734629bfa8fac0c0d8fede5f2b8984a3f4c4e026996ca66916b99d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall googletrans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KF5MezMZI6K",
        "outputId": "45c3e945-dddb-48dd-f305-8cad4369c75d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: googletrans 4.0.0rc1\n",
            "Uninstalling googletrans-4.0.0rc1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/translate\n",
            "    /usr/local/lib/python3.7/dist-packages/googletrans-4.0.0rc1.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/googletrans/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled googletrans-4.0.0rc1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install googletrans==3.1.0a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "9ROTpuQ6mXZU",
        "outputId": "51fff875-98c6-4ece-a88e-1ade2337dfb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting googletrans==4.0.0-rc1\n",
            "  Using cached googletrans-4.0.0rc1-py3-none-any.whl\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.7/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2021.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2022.5.18.1)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.2.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Installing collected packages: googletrans\n",
            "Successfully installed googletrans-4.0.0rc1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "googletrans"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fsspec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH-jYaEEYNEW",
        "outputId": "d2abf923-b9cf-4d79-e7b3-d787d6f607cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (2022.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandera"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_fUeeRrYQgR",
        "outputId": "39b6682a-a794-4627-ffbd-a0ac107e73f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandera\n",
            "  Downloading pandera-0.9.0-py3-none-any.whl (197 kB)\n",
            "\u001b[K     |████████████████████████████████| 197 kB 27.1 MB/s \n",
            "\u001b[?25hCollecting typing-inspect>=0.6.0\n",
            "  Downloading typing_inspect-0.7.1-py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from pandera) (1.21.6)\n",
            "Collecting pydantic\n",
            "  Downloading pydantic-1.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1 MB 38.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from pandera) (6.0.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from pandera) (1.3.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from pandera) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pandera) (4.2.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from pandera) (1.14.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->pandera) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->pandera) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->pandera) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->pandera) (1.15.0)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Installing collected packages: mypy-extensions, typing-inspect, pydantic, pandera\n",
            "Successfully installed mypy-extensions-0.4.3 pandera-0.9.0 pydantic-1.9.1 typing-inspect-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install translate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj5hIw53o29-",
        "outputId": "8d8fd7c9-c3d3-4819-cd54-3f2d68c2cc08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting translate\n",
            "  Downloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from translate) (4.2.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from translate) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from translate) (7.1.2)\n",
            "Collecting libretranslatepy==2.1.1\n",
            "  Downloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->translate) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->translate) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->translate) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->translate) (2022.5.18.1)\n",
            "Installing collected packages: libretranslatepy, translate\n",
            "Successfully installed libretranslatepy-2.1.1 translate-3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vr3_Dat0SDR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.cloud import storage\n",
        "import googletrans \n",
        "from googletrans import Translator\n",
        "from pymongo import MongoClient\n",
        "from datetime import date\n",
        "import os\n",
        "import gcsfs\n",
        "# from translate import Translator\n",
        "# import translate"
      ],
      "metadata": {
        "id": "xEQQrB-2Iao5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Montando o Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8hner13InKR",
        "outputId": "f214823a-96e2-4db6-f542-0d8c304822bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CONFIGURAÇÃO DA CHAVE DE SEGURANÇA\n",
        "serviceAccount = '/content/drive/MyDrive/Acesso GCP/hopeful-list-349119-f034072f7a24.json'\n",
        "\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = serviceAccount"
      ],
      "metadata": {
        "id": "J5atPprEIplq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CÓDIGO QUE ACESSA MEU BUCKET CRIADA E FAZ O DOWNLOAD DOS ARQUIVOS VIA PANDAS\n",
        "client = storage.Client()\n",
        "\n",
        "bucket = client.get_bucket('projetoindividual')\n",
        "\n",
        "bucket.blob('marketing_campaign.csv')\n",
        "\n",
        "path = 'gs://projetoindividual/Original/marketing_campaign.csv'\n"
      ],
      "metadata": {
        "id": "-9UPheDtIrvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Carregadno o CSV direto do Claudio***"
      ],
      "metadata": {
        "id": "IBfkAHO6eNJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(r'gs://projetoindividual/Original/marketing_campaign.csv', sep=';', encoding='utf-8')"
      ],
      "metadata": {
        "id": "0GIyi0RzJmos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Fazendo uma pré análise dos dados obtidos***"
      ],
      "metadata": {
        "id": "C-LEnhwNHDWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Função utilizada para filtrar e calcular a quantidade de resgistros em branco, e a proporção dessa perda antes do ETL.\n",
        "def dados_perdidos(df):\n",
        "    perdas = df.isna().sum()\n",
        "    perdas = perdas[perdas >0 ]\n",
        "    perdas_proporcionais = perdas/df.shape[0]\n",
        "    perdas_totais = perdas_proporcionais > 0.05\n",
        "\n",
        "    return pd.DataFrame({\"Perdas\" : perdas, \"Proporção de perdas\" : perdas_proporcionais, \"Perdas maiores que 5%\" : perdas_totais})\n",
        "\n",
        "\n",
        "dados_perdidos(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "G91c5Lz2ADPx",
        "outputId": "7a081230-b248-4e3f-adf6-13e964a562b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Perdas  Proporção de perdas  Perdas maiores que 5%\n",
              "Income      24             0.010714                  False"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06962748-695a-4b92-baeb-a8e2262c171d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Perdas</th>\n",
              "      <th>Proporção de perdas</th>\n",
              "      <th>Perdas maiores que 5%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Income</th>\n",
              "      <td>24</td>\n",
              "      <td>0.010714</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06962748-695a-4b92-baeb-a8e2262c171d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06962748-695a-4b92-baeb-a8e2262c171d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06962748-695a-4b92-baeb-a8e2262c171d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fazendo um backup do dataframe\n",
        "df1_pt = df.copy()"
      ],
      "metadata": {
        "id": "8lKnD6bgAQ3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***O csv está com a liguagem em inglês ('en'), também foram encontradas as seguintes inconsistências:\n",
        "\"COLUNA EDUCAÇÃO = AQUELE CICLO\", \n",
        "\"COLUNA ESTADO CIVIL = JUNTOS\",\n",
        "\"COLUNA RENDA POSSUI 24 CAMPOS EM BRANCO\" \n",
        "\"COLUNA = DT_CUSTORMER, ESTÁ EM FORMATO OBJECT\".***"
      ],
      "metadata": {
        "id": "P9JB7kzbHMx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPARANDO CORREÇÕES E APLICANDO A TRADUÇÃO NO DATAFRAME"
      ],
      "metadata": {
        "id": "zocOVnMYeenm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Conferindo as siglas correspondentes para a tradução\n",
        "print(googletrans.LANGUAGES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRv0pexMafE8",
        "outputId": "5b376722-70f9-4975-bc4a-ea70b28cdeed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'af': 'afrikaans', 'sq': 'albanian', 'am': 'amharic', 'ar': 'arabic', 'hy': 'armenian', 'az': 'azerbaijani', 'eu': 'basque', 'be': 'belarusian', 'bn': 'bengali', 'bs': 'bosnian', 'bg': 'bulgarian', 'ca': 'catalan', 'ceb': 'cebuano', 'ny': 'chichewa', 'zh-cn': 'chinese (simplified)', 'zh-tw': 'chinese (traditional)', 'co': 'corsican', 'hr': 'croatian', 'cs': 'czech', 'da': 'danish', 'nl': 'dutch', 'en': 'english', 'eo': 'esperanto', 'et': 'estonian', 'tl': 'filipino', 'fi': 'finnish', 'fr': 'french', 'fy': 'frisian', 'gl': 'galician', 'ka': 'georgian', 'de': 'german', 'el': 'greek', 'gu': 'gujarati', 'ht': 'haitian creole', 'ha': 'hausa', 'haw': 'hawaiian', 'iw': 'hebrew', 'he': 'hebrew', 'hi': 'hindi', 'hmn': 'hmong', 'hu': 'hungarian', 'is': 'icelandic', 'ig': 'igbo', 'id': 'indonesian', 'ga': 'irish', 'it': 'italian', 'ja': 'japanese', 'jw': 'javanese', 'kn': 'kannada', 'kk': 'kazakh', 'km': 'khmer', 'ko': 'korean', 'ku': 'kurdish (kurmanji)', 'ky': 'kyrgyz', 'lo': 'lao', 'la': 'latin', 'lv': 'latvian', 'lt': 'lithuanian', 'lb': 'luxembourgish', 'mk': 'macedonian', 'mg': 'malagasy', 'ms': 'malay', 'ml': 'malayalam', 'mt': 'maltese', 'mi': 'maori', 'mr': 'marathi', 'mn': 'mongolian', 'my': 'myanmar (burmese)', 'ne': 'nepali', 'no': 'norwegian', 'or': 'odia', 'ps': 'pashto', 'fa': 'persian', 'pl': 'polish', 'pt': 'portuguese', 'pa': 'punjabi', 'ro': 'romanian', 'ru': 'russian', 'sm': 'samoan', 'gd': 'scots gaelic', 'sr': 'serbian', 'st': 'sesotho', 'sn': 'shona', 'sd': 'sindhi', 'si': 'sinhala', 'sk': 'slovak', 'sl': 'slovenian', 'so': 'somali', 'es': 'spanish', 'su': 'sundanese', 'sw': 'swahili', 'sv': 'swedish', 'tg': 'tajik', 'ta': 'tamil', 'te': 'telugu', 'th': 'thai', 'tr': 'turkish', 'uk': 'ukrainian', 'ur': 'urdu', 'ug': 'uyghur', 'uz': 'uzbek', 'vi': 'vietnamese', 'cy': 'welsh', 'xh': 'xhosa', 'yi': 'yiddish', 'yo': 'yoruba', 'zu': 'zulu'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Atribuindo o translator em uma variável\n",
        "tradutor = Translator()\n"
      ],
      "metadata": {
        "id": "ZPP9fw5TZsxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Traduzindo as minhas colunas para o formato PT \n",
        "try:\n",
        "  df1_pt.rename(columns=lambda x: tradutor.translate(x, src='en', dest='pt').text, inplace=True)\n",
        "except Exception as e:\n",
        "  print(str(e))"
      ],
      "metadata": {
        "id": "zm6jAJMVJAo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Traduzindo todas as linhas para o formato PT \n",
        "\n",
        "#Criando um dicionário vazio\n",
        "traducoes = {}\n",
        "\n",
        "#Estrutura de repetição que vai percorrer verificar e todas colunas no dataframe\n",
        "for colunas in df1_pt.columns:\n",
        "    \n",
        "    #Procurando elementos unicos no dataframe\n",
        "    elementos_unicos = df1_pt[colunas].unique()\n",
        "    \n",
        "    #Estrutura de repetição que vai percorrer cada um dos elementos, traduzi-los e adicionar essa tradução dentro do meu dicionário\n",
        "    for elemento in elementos_unicos:\n",
        "        traducoes[elemento] = tradutor.translate(elemento, dest='pt').text"
      ],
      "metadata": {
        "id": "McREnkRqqqG-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "586f31ea-0cff-457f-fbe7-6f60f1cc7696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-003116ca84a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#Estrutura de repetição que vai percorrer cada um dos elementos, traduzi-los e adicionar essa tradução dentro do meu dicionário\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0melemento\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melementos_unicos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtraducoes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melemento\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtradutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melemento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googletrans/client.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0morigin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mtoken_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googletrans/client.py\u001b[0m in \u001b[0;36m_translate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRANSLATE_RPC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pick_service_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         data = {\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0;34m'f.req'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_rpc_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         }\n\u001b[1;32m    112\u001b[0m         params = {\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googletrans/client.py\u001b[0m in \u001b[0;36m_build_rpc_request\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m     94\u001b[0m             [\n\u001b[1;32m     95\u001b[0m                 \u001b[0mRPC_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;34m'generic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
            "\u001b[0;32m/usr/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Object of type int64 is not JSON serializable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1_pt.replace(traducoes, inplace = True)"
      ],
      "metadata": {
        "id": "g_VGbQK_xZK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Corrigindo manualmente a falha de tradução do google translate\n",
        "colunas_traduzidas = (['ID', 'Ano_Nascimento', 'Escolaridade', 'Estado_civil', 'Renda', 'Qtde_Crianças_no_lar', 'Qtde_Adolescentes_no_lar',\n",
        "             'Data_do_cadastro', 'Dias_da_ultima_compra', 'Gasto_com_vinho', 'Gasto_com_frutas', 'Gasto_com_carnes', 'Gasto_frutos_do_mar', 'Gasto_com_doces', \n",
        "             'Produtos_ouro', 'Compras_com_desconto', 'Compras_online', 'Compras_no_catalogo', 'Compras_na_loja', 'Visitas_no_website', 'campanhas_aceitas_01',\n",
        "             'Campanhas_aceitas02', 'Campanhas_aceitas_03', 'Campanhas_aceitas_04', 'Campanhas_aceitas_05', 'Reclamações', 'Custo_do_Contato','Receita', 'Oferta_aceita']\n",
        "    \n",
        ")\n",
        "df1_pt.columns = colunas_traduzidas\n",
        "df1_pt"
      ],
      "metadata": {
        "id": "420d773MqwJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aplicando replace nos campos que não foram traduzidos corretamente, e corrigindo campos com erro de escrita\n",
        "df1_pt.replace(to_replace = 'Juntos', value = 'União Estável', inplace=True)\n",
        "df1_pt.replace(to_replace = 'aquele ciclo', value = 'N/E', inplace=True)\n"
      ],
      "metadata": {
        "id": "R0RVxme9KL4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fazendo a correção da coluna Data_do_cadastro que estava no tipo de texto para o tipo DATE-TIME\n",
        "df1_pt['Data_do_cadastro'] = pd.to_datetime(df1_pt['Data_do_cadastro'], errors='coerce')\n"
      ],
      "metadata": {
        "id": "g6Gddwu_3JNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aplicando tratamento para os campos nulos\n",
        "# df1_pt.replace({\"\":np.nan})\n",
        "df1_pt.fillna(value = 0, inplace=True)"
      ],
      "metadata": {
        "id": "MLXaabSGkidU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chamando a função novamente para fazer um novo cálculo apos o ETL.\n",
        "dados_perdidos(df1_pt)"
      ],
      "metadata": {
        "id": "SY0HnJLZuHvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***USANDO O SPARK PARA TRATAR DADOS QUE NÃO FORAM POSSÍVEIS COM O PANDAS***"
      ],
      "metadata": {
        "id": "YOc-XV2lD8HC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CHAMAR AS BIBLIOTECAS/MÓDULOS NECESSÁRIAS Pyspark\n",
        "from pyspark import SparkConf\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, LongType, StringType, FloatType"
      ],
      "metadata": {
        "id": "qAZqs3nXFahU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CRIAR A SPARK SESSION E LER O ARQUIVO VIA PYSPARK\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "                .master('local')\n",
        "                .appName('spark-gcs')\n",
        "                .config('spark.ui.port', '4050')\n",
        "                .config(\"spark.jars\", 'https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-hadoop2-latest.jar')\n",
        "                .getOrCreate()\n",
        ")"
      ],
      "metadata": {
        "id": "o-cmcKGnF3st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Puxando o dataframe tratado em pandas e transformando em um dataframe Pyspark\n",
        "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
        "df_spark = spark.createDataFrame(df1_pt)"
      ],
      "metadata": {
        "id": "fyzd_WgnEBuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Fazendo uma análise pós tratamento com pandas.***"
      ],
      "metadata": {
        "id": "RyCkX6U0uRGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YCq5z31zudrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.printSchema()"
      ],
      "metadata": {
        "id": "-RtylVviuge3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Removendo colunas que apresentam inconsistências e que podem gerar erro na análise final.***\n",
        "***Colunas: ID, Custo do contato, Receita***"
      ],
      "metadata": {
        "id": "RTmnuNNhvuyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropando a colunas ID, Custo do contato, Receita \n",
        "df_spark = df_spark.drop(F.col('ID'))\n",
        "df_spark = df_spark.drop(F.col('Custo_do_Contato'))\n",
        "df_spark = df_spark.drop(F.col('Receita'))"
      ],
      "metadata": {
        "id": "Yd7QGAG-IFP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo a coluna para o tipo DATE\n",
        "df_spark.select(F.col('Data_do_Cadastro'), F.to_date(F.col('Data_do_Cadastro'), 'yyyy-MM-dd')).printSchema()\n",
        "df_data = df_spark.select(F.col('Data_do_Cadastro'), F.to_date(F.col('Data_do_Cadastro'), 'dd-MM-yy').alias('Data_do_cadastro_BR'))"
      ],
      "metadata": {
        "id": "YU9ZrfIj9EMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.select(F.col('Data_do_Cadastro'), F.date_format(F.col('Data_do_Cadastro'), 'dd-MM-yyyy').alias('Data_do_cadastro_BR')).printSchema()"
      ],
      "metadata": {
        "id": "Iz7m3Grp-Fkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.withColumn('Data_do_cadastro_BR', F.current_date()).show()"
      ],
      "metadata": {
        "id": "K5szC3A48Fw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Organizando o schema pelo ano de nascimento\n",
        "df_spark.orderBy(F.col('Ano_Nascimento').desc()).show(100, truncate=False)"
      ],
      "metadata": {
        "id": "_twazrhzHYvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removendo o registro 'Pedalar\" da coluna Escolaridade\n",
        "df_spark = ( df_spark.withColumn('Escolaridade', F.regexp_replace(F.col('Escolaridade'), 'pedalar', ''))\n",
        "                      .withColumn('Renda', F.regexp_replace(F.col('Renda'), 'dentro', ''))\n",
        ")"
      ],
      "metadata": {
        "id": "ueg_lmuQx-Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SUBSTITUIÇÃO DE VALORES NULOS\n",
        "df_spark.fillna(\"NA\", subset=['Escolaridade', 'Renda']).show()"
      ],
      "metadata": {
        "id": "Jx54aqHq1U0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removendo duplicatas nos resgistros\n",
        "df_spark.dropDuplicates().count()"
      ],
      "metadata": {
        "id": "N7-UwcHAIjta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verificando a quantidade dos dados duplicados\n",
        "total = (df_spark.count()) - (df_spark.dropDuplicates().count())\n",
        "print(total)"
      ],
      "metadata": {
        "id": "vUj7Fb3kIz6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Alterando o nome das colunas\n",
        "# df_spark = df_spark.withColumnRenamed(\"Qtde_Crianças_no_lar\", \"Qtde_Crianças_em_casa\")\n",
        "# df_spark = df_spark.withColumnRenamed(\"Qtde_Adolescentes_no_lar\", \"Qtde_Adolescentes_em_casa\")"
      ],
      "metadata": {
        "id": "G92OosabHAg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Criando uma nova coluna com o total de compras feitas\n",
        "df_spark = df_spark.withColumn('total_compras', F.col('Compras_online') + F.col('Compras_no_catalogo') + F.col('Compras_na_loja') + F.col('Compras_com_desconto'))"
      ],
      "metadata": {
        "id": "ooUHw_aZHnOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Criando uma nova coluna com total de gastos\n",
        "df_spark = df_spark.withColumn('total_gastos', F.col('Gasto_com_vinho') + F.col('Gasto_com_frutas') + F.col('Gasto_com_carnes') + F.col('Gasto_com_frutos_do_mar') + F.col('Gasto_com_doces') + F.col('Produtos_ouro'))"
      ],
      "metadata": {
        "id": "C9FdyOWKH8Wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar a escolariade das pessoas e o total de compras\n",
        "df_spark.groupBy('Escolaridade').sum('total_compras').show()"
      ],
      "metadata": {
        "id": "CMi_m9esIip2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar o cliente mais velho\n",
        "df_spark.orderBy(F.col('Ano_nascimento').asc()).show()"
      ],
      "metadata": {
        "id": "UXi_bds5I0fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar o cliente mais jovem\n",
        "df_spark.orderBy(F.col('Ano_nascimento').desc()).show()"
      ],
      "metadata": {
        "id": "ZRYblHrhI3s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar o cliente com a maior renda \n",
        "df_spark.orderBy(F.col('Renda').desc()).show()"
      ],
      "metadata": {
        "id": "ENEgfdcxI_ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar o cliente que gastou mais\n",
        "df_spark.orderBy(F.col('total_gastos').desc()).show()"
      ],
      "metadata": {
        "id": "a4H0FPx5JEw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verificar a qtde de pessoas e seu nivel de escolaridade\n",
        "df_spark.groupBy('Escolaridade').count().show()"
      ],
      "metadata": {
        "id": "oEznFS5bJLZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar a média da Renda familiar anual e o nivel de escolaridade\n",
        "df_spark.groupBy('Escolaridade').agg(F.avg('Renda')).show()"
      ],
      "metadata": {
        "id": "T7sbA0kvJRd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Finalizando o trabalho***"
      ],
      "metadata": {
        "id": "0dnCu-7rKIsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformando o dataframe Pyspark em csv\n",
        "df_spark.toPandas().to_csv('gs://projetoindividual/Tratado', index=False)"
      ],
      "metadata": {
        "id": "cpgsloRCKOCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_tratado = 'projetoindividual/Tratado/campanha_marketing.csv'"
      ],
      "metadata": {
        "id": "wu4VZSMvKhYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tratado = pd.read_csv(path_tratado, sep=',')"
      ],
      "metadata": {
        "id": "ZVo9pWEpMFMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = client['soulcode']"
      ],
      "metadata": {
        "id": "fUZ4sELRMN-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collection = db['projeto_individual']"
      ],
      "metadata": {
        "id": "K8oe9_xDO4oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dicio = df_tratado.to_dict(\"records\")"
      ],
      "metadata": {
        "id": "Ebh4Mgp8PEvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collection.insert_many(df_dicio)"
      ],
      "metadata": {
        "id": "ZjrfUFpVPJ3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#enviando para o bucket GCP\n",
        "df_dicio.to_csv('gs://projetoindividual/Tratado')"
      ],
      "metadata": {
        "id": "wNCCNHoGPVp5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}